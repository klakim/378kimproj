{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"model\"\n",
        "format: html\n",
        "---"
      ],
      "id": "55517534"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from palmerpenguins import penguins\n",
        "from pandas import get_dummies\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "id": "40cc14ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Data fixed 3/7\n"
      ],
      "id": "00e3b637"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = penguins.load_penguins().dropna()\n",
        "\n",
        "df.head(3)"
      ],
      "id": "78ba33d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Model and Fit\n"
      ],
      "id": "3cb95b01"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = get_dummies(df[['bill_length_mm', 'species', 'sex']], drop_first = True)\n",
        "y = df['body_mass_g']\n",
        "\n",
        "#context for building the api\n",
        "print(X)\n",
        "model = LinearRegression().fit(X, y)"
      ],
      "id": "2c4f64d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get some information\n"
      ],
      "id": "e5680753"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"R^2 {model.score(X,y)}\")\n",
        "print(f\"Intercept {model.intercept_}\")\n",
        "print(f\"Columns {X.columns}\")\n",
        "print(f\"Coefficients {model.coef_}\")"
      ],
      "id": "b61e40f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attempt at Model Validation\n"
      ],
      "id": "1894a46e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% training and 20% testing\n",
        "\n",
        "model = LinearRegression().fit(X_train, y_train)\n",
        "#Asked Chat GPT on what statistics to run on \n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'R-squared (RÂ²): {r2}')"
      ],
      "id": "3c888435",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2\n"
      ],
      "id": "ae47e65e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from joblib import dump\n",
        "dump(model, 'penguin_model.pkl')"
      ],
      "id": "67a5c0aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from vetiver import VetiverModel\n",
        "\n",
        "v = VetiverModel(model=model, model_name='penguin_model', prototype_data=X)"
      ],
      "id": "645cd1d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pins import board_folder\n",
        "from vetiver import vetiver_pin_write\n",
        "\n",
        "# Initialize board folder\n",
        "model_board = board_folder(\"finalproj/pins-py\", allow_pickle_read=True)\n",
        "\n",
        "# Write the Vetiver model to the board\n",
        "vetiver_pin_write(model_board, v)\n"
      ],
      "id": "92313b8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from vetiver import VetiverAPI\n",
        "app = VetiverAPI(v, check_prototype=True)"
      ],
      "id": "14004da3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#vetiver.prepare_docker(model_board, \"penguin_model\")"
      ],
      "id": "2509293f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from vetiver.server import predict, vetiver_endpoint\n",
        "endpoint = vetiver_endpoint(\"http://127.0.0.1:8080/predict\")\n",
        "endpoint"
      ],
      "id": "b7b23274",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Correct the dictionary format and structure for DataFrame creation\n",
        "new_penguin_dict = {\n",
        "    \"bill_length_mm\": [120],  # Enclosed the values in lists\n",
        "    \"sex_male\": [1],          # Assuming '1' for male based on your previous messages\n",
        "    \"species_Gentoo\": [1],\n",
        "    \"species_Chinstrap\": [0]\n",
        "}\n",
        "\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "record_dict = new_penguin.iloc[0].to_dict()\n",
        "\n",
        "import requests  # Ensure this is installed: pip install requests\n",
        "\n",
        "# Assuming 'endpoint' is your API endpoint URL\n",
        "response = requests.post(endpoint, json=record_dict)\n",
        "\n",
        "# Check the response\n",
        "if response.ok:\n",
        "    print(\"Success:\", response.json())\n",
        "else:\n",
        "    print(\"Error:\", response.status_code, response.text)"
      ],
      "id": "60f70ac4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import duckdb\n",
        "from palmerpenguins import penguins\n",
        "\n",
        "con = duckdb.connect('my-db.duckdb')\n",
        "df = con.execute(\"SELECT * FROM penguins\").fetchdf().dropna()\n",
        "con.close()"
      ],
      "id": "dfe713b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Documentation Statement: I used the following resource : <https://www.geeksforgeeks.org/how-to-do-train-test-split-using-sklearn-in-python/>"
      ],
      "id": "fd424018"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}