[
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "model",
    "section": "",
    "text": "from palmerpenguins import penguins\nfrom pandas import get_dummies\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
  },
  {
    "objectID": "model.html#model",
    "href": "model.html#model",
    "title": "model",
    "section": "Model:",
    "text": "Model:\n\ndf = penguins.load_penguins().dropna()\n\ndf.head(3)\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007"
  },
  {
    "objectID": "model.html#define-model-and-fit",
    "href": "model.html#define-model-and-fit",
    "title": "model",
    "section": "Define Model and Fit",
    "text": "Define Model and Fit\n\nX = get_dummies(df[['bill_length_mm', 'species', 'sex']], drop_first = True)\ny = df['body_mass_g']\n\n#context for building the api\nprint(X)\nmodel = LinearRegression().fit(X, y)\n\n     bill_length_mm  species_Chinstrap  species_Gentoo  sex_male\n0              39.1              False           False      True\n1              39.5              False           False     False\n2              40.3              False           False     False\n4              36.7              False           False     False\n5              39.3              False           False      True\n..              ...                ...             ...       ...\n339            55.8               True           False      True\n340            43.5               True           False     False\n341            49.6               True           False      True\n342            50.8               True           False      True\n343            50.2               True           False     False\n\n[333 rows x 4 columns]"
  },
  {
    "objectID": "model.html#get-some-information",
    "href": "model.html#get-some-information",
    "title": "model",
    "section": "Get some information",
    "text": "Get some information\n\nprint(f\"R^2 {model.score(X,y)}\")\nprint(f\"Intercept {model.intercept_}\")\nprint(f\"Columns {X.columns}\")\nprint(f\"Coefficients {model.coef_}\")\n\nR^2 0.8555368759537614\nIntercept 2169.2697209393996\nColumns Index(['bill_length_mm', 'species_Chinstrap', 'species_Gentoo', 'sex_male'], dtype='object')\nCoefficients [  32.53688677 -298.76553447 1094.86739145  547.36692408]"
  },
  {
    "objectID": "model.html#attempt-at-model-validation",
    "href": "model.html#attempt-at-model-validation",
    "title": "model",
    "section": "Attempt at Model Validation",
    "text": "Attempt at Model Validation\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% training and 20% testing\n\nmodel = LinearRegression().fit(X_train, y_train)\n#Asked Chat GPT on what statistics to run on \ny_pred = model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f'Mean Squared Error (MSE): {mse}')\nprint(f'Mean Absolute Error (MAE): {mae}')\nprint(f'R-squared (R²): {r2}')\n\nMean Squared Error (MSE): 96276.55445316953\nMean Absolute Error (MAE): 247.01332715906779\nR-squared (R²): 0.838967354416846"
  },
  {
    "objectID": "model.html#chapter-2",
    "href": "model.html#chapter-2",
    "title": "model",
    "section": "Chapter 2",
    "text": "Chapter 2\n\nfrom joblib import dump\ndump(model, 'penguin_model.pkl')\n\n['penguin_model.pkl']\n\n\n\nfrom vetiver import VetiverModel\n\nv = VetiverModel(model=model, model_name='penguin_model', prototype_data=X)\n\n\n#from pins import board_folder\n#from vetiver import vetiver_pin_write\n\n# Initialize board folder\n#model_board = board_folder(\"finalproj/pins-py\", allow_pickle_read=True)\n\n# Write the Vetiver model to the board\n#vetiver_pin_write(model_board, v)\n\n\n#Script from chatGPT on how to move contents in one folder to another\n\nimport os\nimport shutil\n\ndef copy_directory_contents(src_dir, dest_dir):\n    # Check if source directory exists\n    if not os.path.exists(src_dir):\n        print(f\"Source directory {src_dir} does not exist.\")\n        return\n\n    # Check if destination directory exists; if not, create it\n    if not os.path.exists(dest_dir):\n        os.makedirs(dest_dir)\n\n    # List all files and directories in the source directory\n    for item in os.listdir(src_dir):\n        src_path = os.path.join(src_dir, item)\n        dest_path = os.path.join(dest_dir, item)\n\n        # Check whether the current item is a directory or a file\n        if os.path.isdir(src_path):\n            # Recursively copy a directory\n            shutil.copytree(src_path, dest_path, dirs_exist_ok=True)\n        else:\n            # Copy a single file\n            shutil.copy2(src_path, dest_path)\n\n# Specify your source and destination paths\nsource_directory = 'pins-py'\ndestination_directory = 'data/model'\n\n# Copy the contents from source to destination\ncopy_directory_contents(source_directory, destination_directory)\n\n\n#from vetiver import VetiverAPI\n#app = VetiverAPI(v, check_prototype=True)\n\n\n#vetiver.prepare_docker(model_board, \"penguin_model\")\n\n\n#from vetiver.server import predict, vetiver_endpoint\n#endpoint = vetiver_endpoint(\"http://127.0.0.1:8080/predict\")\n#endpoint\n\n\n#import pandas as pd\n\n# Your existing dictionary\n#new_penguin_dict = {\n#    \"bill_length_mm\": [120],  # Enclosed the values in lists\n#    \"sex_male\": [1],          # Assuming '1' for male based on your previous messages\n#    \"species_Gentoo\": [1],\n#    \"species_Chinstrap\": [0]\n#}\n\n# Convert the dictionary to a DataFrame\n#new_penguin_df = pd.DataFrame(new_penguin_dict)\n\n# Now, convert the first row of the DataFrame to a dictionary\n#record_dict = new_penguin_df.iloc[0].to_dict()\n\n\n#import requests  # Ensure this is installed: pip install requests\n\n# Assuming 'endpoint' is your API endpoint URL\n#response = requests.post(endpoint, json=record_dict)\n\n# Check the response\n#if response.ok:\n   # print(\"Success:\", response.json())\n#else:\n   # print(\"Error:\", response.status_code, response.text)\n\n\n#if(FALSE) {\n#  import duckdb\n#  from palmerpenguins import penguins\n\n#con = duckdb.connect('my-db.duckdb')\n#df = con.execute(\"SELECT * FROM penguins\").fetchdf().dropna()\n#con.close()\n#}\n\nDocumentation Statement: I used the following resource : https://www.geeksforgeeks.org/how-to-do-train-test-split-using-sklearn-in-python/."
  },
  {
    "objectID": "eda.html#penguin-size-and-mass-by-sex-and-species",
    "href": "eda.html#penguin-size-and-mass-by-sex-and-species",
    "title": "eda.qmd",
    "section": "Penguin Size and Mass by Sex and Species",
    "text": "Penguin Size and Mass by Sex and Species\n\n#Needed Packages\ninstall.packages(\"palmerpenguins\")\n\nThe following package(s) will be installed:\n- palmerpenguins [0.1.1]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing palmerpenguins ...                 OK [linked from cache]\nSuccessfully installed 1 package in 7 milliseconds.\n\ninstall.packages(\"dplyr\")\n\nThe following package(s) will be installed:\n- dplyr [1.1.4]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing dplyr ...                          OK [linked from cache]\nSuccessfully installed 1 package in 5.5 milliseconds.\n\ninstall.packages(\"dbplyr\")\n\nThe following package(s) will be installed:\n- dbplyr     [2.5.0]\n- tidyselect [1.2.1]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing tidyselect ...                     OK [linked from cache]\n- Installing dbplyr ...                         OK [linked from cache]\nSuccessfully installed 2 packages in 8.5 milliseconds.\n\ninstall.packages(\"ggplot2\")\n\nThe following package(s) will be installed:\n- ggplot2 [3.5.0]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing ggplot2 ...                        OK [linked from cache]\nSuccessfully installed 1 package in 5.9 milliseconds.\n\ninstall.packages(\"DBI\")\n\nThe following package(s) will be installed:\n- DBI [1.2.2]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing DBI ...                            OK [linked from cache]\nSuccessfully installed 1 package in 5.9 milliseconds.\n\ninstall.packages(\"duckdb\")\n\nThe following package(s) will be installed:\n- duckdb [0.10.1]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing duckdb ...                         OK [linked from cache]\nSuccessfully installed 1 package in 7.7 milliseconds.\n\ninstall.packages(\"vetiver\")\n\nThe following package(s) will be installed:\n- vetiver [0.2.5]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing vetiver ...                        OK [linked from cache]\nSuccessfully installed 1 package in 5.4 milliseconds.\n\ninstall.packages(\"tidyverse\")\n\nThe following package(s) will be installed:\n- tidyverse [2.0.0]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing tidyverse ...                      OK [linked from cache]\nSuccessfully installed 1 package in 5.5 milliseconds.\n\ninstall.packages(\"ISLR2\")\n\nThe following package(s) will be installed:\n- ISLR2 [1.3-2]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing ISLR2 ...                          OK [linked from cache]\nSuccessfully installed 1 package in 5.3 milliseconds.\n\ninstall.packages(\"rpart.plot\")\n\nThe following package(s) will be installed:\n- rpart.plot [3.1.2]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing rpart.plot ...                     OK [linked from cache]\nSuccessfully installed 1 package in 5.1 milliseconds.\n\ninstall.packages(\"vip\")\n\nThe following package(s) will be installed:\n- vip [0.4.1]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing vip ...                            OK [linked from cache]\nSuccessfully installed 1 package in 5.4 milliseconds.\n\ninstall.packages(\"randomForest\")\n\nThe following package(s) will be installed:\n- randomForest [4.7-1.1]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing randomForest ...                   OK [linked from cache]\nSuccessfully installed 1 package in 5.2 milliseconds.\n\ninstall.packages(\"tidymodels\")\n\nThe following package(s) will be installed:\n- doFuture     [1.0.1]\n- parsnip      [1.2.1]\n- rsample      [1.2.1]\n- rstudioapi   [0.16.0]\n- tidymodels   [1.2.0]\n- tune         [1.2.1]\n- workflowsets [1.1.0]\n- yardstick    [1.3.1]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing parsnip ...                        OK [linked from cache]\n- Installing rsample ...                        OK [linked from cache]\n- Installing rstudioapi ...                     OK [linked from cache]\n- Installing doFuture ...                       OK [linked from cache]\n- Installing yardstick ...                      OK [linked from cache]\n- Installing tune ...                           OK [linked from cache]\n- Installing workflowsets ...                   OK [linked from cache]\n- Installing tidymodels ...                     OK [linked from cache]\nSuccessfully installed 8 packages in 25 milliseconds.\n\ninstall.packages(\"xgboost\")\n\nThe following package(s) will be installed:\n- xgboost [1.7.7.1]\nThese packages will be installed into \"~/work/378kimproj/378kimproj/renv/library/R-4.2/x86_64-pc-linux-gnu\".\n\n# Installing packages --------------------------------------------------------\n- Installing xgboost ...                        OK [linked from cache]\nSuccessfully installed 1 package in 5.4 milliseconds.\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb(), dbdir = \"my-db.duckdb\")\nDBI::dbWriteTable(con, \"penguins\", palmerpenguins::penguins, overwrite = TRUE)\n\n\n#Load packages \nlibrary(palmerpenguins)\nlibrary(dplyr)\nlibrary(dbplyr)\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(DBI)\nlibrary(vetiver)\nlibrary(pins)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ISLR2)\nlibrary(rpart.plot)\nlibrary(vip)\nlibrary(xgboost)\nlibrary(randomForest)\n\n\n\n#load data \ncon &lt;- DBI::dbConnect(\n  duckdb::duckdb(), \n  dbdir = \"my-db.duckdb\"\n  )\ndf &lt;- dplyr::tbl(con, \"penguins\")\n\n\n#From Chapter 1\ndf %&gt;%\n  group_by(species, sex) %&gt;%\n  summarise(\n    across(\n        ends_with(\"mm\") | ends_with(\"g\"),\n      \\(x) mean(x, na.rm = TRUE)\n      )\n    ) %&gt;%\n  dplyr::collect() %&gt;%\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nsex\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\nAdelie\nNA\n37.84000\n18.32000\n185.6000\n3540.000\n\n\nAdelie\nfemale\n37.25753\n17.62192\n187.7945\n3368.836\n\n\nAdelie\nmale\n40.39041\n19.07260\n192.4110\n4043.493\n\n\nChinstrap\nfemale\n46.57353\n17.58824\n191.7353\n3527.206\n\n\nChinstrap\nmale\n51.09412\n19.25294\n199.9118\n3938.971\n\n\nGentoo\nNA\n45.62500\n14.55000\n215.7500\n4587.500\n\n\nGentoo\nfemale\n45.56379\n14.23793\n212.7069\n4679.741\n\n\nGentoo\nmale\n49.47377\n15.71803\n221.5410\n5484.836\n\n\n\n\n\n\n#Given EDA\ndf %&gt;%\n  ggplot(aes(x = bill_length_mm, y = body_mass_g, color = species)) +\n  geom_point() + \n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "eda.html#penguin-bill-length-by-sex-and-species",
    "href": "eda.html#penguin-bill-length-by-sex-and-species",
    "title": "eda.qmd",
    "section": "Penguin Bill Length by Sex and Species",
    "text": "Penguin Bill Length by Sex and Species\n\n# Boxplot for comparison \ndf%&gt;%\n  #formula \n  ggplot(aes(x=species, y = bill_length_mm, fill = species))+ \n  #creation\n  geom_boxplot() + \n  theme_minimal() +\n  labs(title = \"Comparison of Bill Length by Species \", x = \"Species\", y = \"Bill Length (mm)\")\n\n\n\n\n\n\n\n\n\n# Boxplot for comparison \ndf%&gt;%\n  #formula \n  ggplot(aes(x=sex, y = bill_length_mm, fill = species))+ \n  #creation\n  geom_boxplot() + \n  theme_minimal() +\n  labs(title = \"Comparison of Bill Length by Sex \", x = \"Sex\", y = \"Bill Length (mm)\")"
  },
  {
    "objectID": "eda.html#penguin-bill-length-by-interaction-of-sex-and-species",
    "href": "eda.html#penguin-bill-length-by-interaction-of-sex-and-species",
    "title": "eda.qmd",
    "section": "Penguin Bill Length by Interaction of Sex and Species",
    "text": "Penguin Bill Length by Interaction of Sex and Species\n\ndf %&gt;%\n  ggplot(aes(x = interaction(species, sex), y = bill_length_mm, fill = species)) + \n  geom_boxplot() + \n  theme_minimal() +\n  labs(\n    title = \"Comparison of Bill Length by Sex and Species\",\n    x = \"Species and Sex\",\n    y = \"Bill Length (mm)\",\n    fill = \"Species\"\n  )\n\n\n\n\n\n\n\n\nRandom Forest for Classification by Species\n\nhead(penguins)\n\n# A tibble: 6 × 7\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 1 more variable: sex &lt;fct&gt;\n\n\n\n#Random forest for classification for species\ntree_spec &lt;- decision_tree() %&gt;%   \n  set_engine(\"rpart\")\nclass_tree_spec &lt;- decision_tree() %&gt;%      \n  set_engine(\"rpart\") %&gt;%      \n  set_mode(\"classification\")\n\nclass_tree_fit &lt;- class_tree_spec %&gt;%    \n  fit(species ~ ., data = penguins)\n\n\nclass_tree_fit %&gt;%\n  extract_fit_engine() %&gt;%\n  rpart.plot()\n\nWarning: Cannot retrieve the data used to build the model (so cannot determine roundint and is.binary for the variables).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.\n\n\n\n\n\n\n\n\naugment(class_tree_fit, new_data = penguins) %&gt;%\n  accuracy(truth = species, estimate =.pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.965\n\n\n\nset.seed(1234)\nPenguin_split &lt;- initial_split(penguins)\n\n\n#Train and test\nPenguin_train &lt;- training(Penguin_split)\nPenguin_test &lt;- testing(Penguin_split)\n\n\n#Fit on just the training data set\nclass_tree_fit &lt;- class_tree_spec %&gt;%    \n  fit(species ~ ., data = Penguin_train)   \n\nclass_tree_fit\n\nparsnip model object\n\nn= 258 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 258 137 Adelie (0.468992248 0.205426357 0.325581395)  \n  2) flipper_length_mm&lt; 206.5 171  52 Adelie (0.695906433 0.298245614 0.005847953)  \n    4) bill_length_mm&lt; 43.15 119   3 Adelie (0.974789916 0.025210084 0.000000000) *\n    5) bill_length_mm&gt;=43.15 52   4 Chinstrap (0.057692308 0.923076923 0.019230769) *\n  3) flipper_length_mm&gt;=206.5 87   4 Gentoo (0.022988506 0.022988506 0.954022989) *\n\n\n\naugment(class_tree_fit, new_data = Penguin_train) %&gt;%\n  conf_mat(truth = species, estimate = .pred_class)\n\n           Truth\nPrediction  Adelie Chinstrap Gentoo\n  Adelie       116         3      0\n  Chinstrap      3        48      1\n  Gentoo         2         2     83\n\n\n\naugment(class_tree_fit, new_data = Penguin_train) %&gt;%\n  accuracy(truth = species, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.957\n\n\n\naugment(class_tree_fit, new_data = Penguin_test) %&gt;%\n  conf_mat(truth = species, estimate = .pred_class)\n\n           Truth\nPrediction  Adelie Chinstrap Gentoo\n  Adelie        28         1      0\n  Chinstrap      3        11      0\n  Gentoo         0         3     40\n\n\n\naugment(class_tree_fit, new_data = Penguin_test) %&gt;%\n  accuracy(truth = species, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.919\n\n\n\n#The testing data doesn't perform as well and we get a lower accuracy by around 4%. Let's try to use the cost_complexity option to see if there is a better tree size that will reduce the overfitting that is happening. \nclass_tree_wf &lt;- workflow() %&gt;%\n  add_model(class_tree_spec %&gt;% set_args(cost_complexity = tune())) %&gt;%\n  add_formula(species ~ .)\n\n\n#With this, we need to use k-fold cross validation and a grid of values \nset.seed(1234)\nPenguin_vfold &lt;- vfold_cv(Penguin_train, v = 10, strata = species)\nparam_grid &lt;- grid_regular(cost_complexity(range = c(-3, -1)), levels = 10)\n\n\n#Fitting the model\n#| cache: true \ntune_res &lt;- tune_grid(\n  class_tree_wf, \n  resamples = Penguin_vfold, \n  grid = param_grid, \n  metrics = metric_set(accuracy)\n)\n\n\n#Which cost-complexity results in the highest accuracy \n#| warning: false \nautoplot(tune_res)\n\n\n\n\n\n\n\nbest_complexity &lt;- select_best(tune_res)\n\n\n#Update the cost_complexity and on the full training set \n#| warning: false \nclass_tree_final &lt;- finalize_workflow(class_tree_wf, best_complexity)\nclass_tree_final_fit &lt;- fit(class_tree_final, data = Penguin_train)\nclass_tree_final_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nspecies ~ .\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 258 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 258 137 Adelie (0.468992248 0.205426357 0.325581395)  \n  2) flipper_length_mm&lt; 206.5 171  52 Adelie (0.695906433 0.298245614 0.005847953)  \n    4) bill_length_mm&lt; 43.15 119   3 Adelie (0.974789916 0.025210084 0.000000000) *\n    5) bill_length_mm&gt;=43.15 52   4 Chinstrap (0.057692308 0.923076923 0.019230769) *\n  3) flipper_length_mm&gt;=206.5 87   4 Gentoo (0.022988506 0.022988506 0.954022989) *\n\n\n\n#Final pruned tree \nclass_tree_final_fit %&gt;%      \n  extract_fit_engine() %&gt;%      \n  rpart.plot()\n\n\n\n\n\n\n\n\n\n#Best Accuracy \naugment(class_tree_fit, new_data = Penguin_train) %&gt;%\n  accuracy(truth = species, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.957\n\n\n\n#The output of this is the pruned tree\nclass_tree_final_fit %&gt;%      \n  extract_fit_engine() %&gt;%      \n  rpart.plot()\n\n\n\n\n\n\n\n\n\nDBI::dbDisconnect(con, shutdown = TRUE)"
  },
  {
    "objectID": "About.html",
    "href": "About.html",
    "title": "C2C Kim Final Project - Penguin Exploration",
    "section": "",
    "text": "C2C Kayla Kim Final Project – Palmer Penguin Data Analysis\n\nThroughout this project, I was given the Palmer Penguins dataset and conducted some exploratory analysis. I learned tools to become a better data scientist and learned how to integrate myself with the IT/Admin team. Furthermore, I explored the environments of code, data project architecture, databases and data APIs, logging and monitoring, deployments and code promotion, and employing docker.\nThis dataset contains 3 different penguin species of Adelie, Gentoo, and Chinstrap. It also includes the island, bill_length, bill depth, flipper length, and body mass. I explored the impacts on mass throughout the Exploratory Data Analysis and the Model files."
  }
]